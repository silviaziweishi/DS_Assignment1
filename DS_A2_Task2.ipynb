{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: data preprocessing and restructuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to read csv: 4.540719985961914 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import groupby \n",
    "from collections import OrderedDict\n",
    "import json \n",
    "import time\n",
    "\n",
    "#read the original file\n",
    "#use chunksize to reduce the loading time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df = pd.read_csv('Assignment1_data.csv', dtype={\n",
    "        \"ID\" : str,\n",
    "        \"Date_Time\" : str,\n",
    "        \"Year\": str,\n",
    "        \"Month\":str,\n",
    "        \"Mdate\":str,\n",
    "        \"Day\": str,\n",
    "        \"Time\":str,\n",
    "        \"Sensor_ID\":str,\n",
    "        \"Sensor_Name\":str,\n",
    "        \"Hourly_Counts\":str\n",
    "    })\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"time taken to read csv:\",(end-start),\"sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3574594, 10)\n",
      "rows: 3574594\n",
      "columns: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"shape:\",df.shape)\n",
    "print(\"rows:\", df.shape[0])\n",
    "print(\"columns:\",df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID               Date_Time  Year     Month Mdate     Day Time  \\\n",
      "0  2887628  11/01/2019 05:00:00 PM  2019  November     1  Friday   17   \n",
      "1  2887629  11/01/2019 05:00:00 PM  2019  November     1  Friday   17   \n",
      "2  2887630  11/01/2019 05:00:00 PM  2019  November     1  Friday   17   \n",
      "3  2887631  11/01/2019 05:00:00 PM  2019  November     1  Friday   17   \n",
      "4  2887632  11/01/2019 05:00:00 PM  2019  November     1  Friday   17   \n",
      "\n",
      "  Sensor_ID                   Sensor_Name Hourly_Counts  \n",
      "0        34          Flinders St-Spark La           300  \n",
      "1        39                  Alfred Place           604  \n",
      "2        37               Lygon St (East)           216  \n",
      "3        40  Lonsdale St-Spring St (West)           627  \n",
      "4        36               Queen St (West)           774  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to write json file 1819.2556171417236 sec\n"
     ]
    }
   ],
   "source": [
    "#convert to json file\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "finalList = []\n",
    "finalDict = {}\n",
    "grouped = df.groupby([\"ID\", \"Year\", \"Month\", \"Mdate\", \"Day\", \"Time\", \"Hourly_Counts\"])\n",
    "for key, value in grouped:\n",
    "\n",
    "\n",
    "    dictionary = {}\n",
    "\n",
    "    j = grouped.get_group(key).reset_index(drop=True)\n",
    "    dictionary[\"ID\"] = j.at[0, \"ID\"]\n",
    "    dictionary[\"Year\"] = j.at[0, \"Year\"]\n",
    "    dictionary[\"Month\"] = j.at[0, \"Month\"]\n",
    "    dictionary[\"Mdate\"] = j.at[0, \"Mdate\"]\n",
    "    dictionary[\"Day\"] = j.at[0, \"Day\"]\n",
    "    dictionary[\"Time\"] = j.at[0, \"Time\"]\n",
    "    dictionary[\"Hourly_Counts\"] = j.at[0, \"Hourly_Counts\"]\n",
    "    \n",
    "\n",
    "    dictList = []\n",
    "    anotherDict = {}\n",
    "    for i in j.index:\n",
    "\n",
    "        anotherDict[\"Sensor_ID\"] = j.at[i, \"Sensor_ID\"]\n",
    "        anotherDict[\"Sensor_Name\"] = j.at[i, \"Sensor_Name\"]\n",
    "\n",
    "        dictList.append(anotherDict)\n",
    "\n",
    "    dictionary[\"sensor\"] = dictList\n",
    "\n",
    "\n",
    "    finalList.append(dictionary)\n",
    "\n",
    "import json\n",
    "with open('task2.json', 'w') as outfile:json.dump(finalList, outfile)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"time taken to write json file\",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time taken to read csv: 4.540719985961914 sec\n",
    "time taken to write json file 1819.2556171417236 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: scripts for loading .json file to mongodb database and querying "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#log into aws instance \n",
    "ssh -i s3766402-cosc2406.pem ec2-user@s3766402.cosc2406.route53.aws.rmit.edu.au"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#directory to work on \n",
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use assignment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see performance \n",
    "db.task2.find({\"sensor\":\"40\"}).explain()\n",
    "db.task2.count({\"Year\":\"2019\"}).explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
